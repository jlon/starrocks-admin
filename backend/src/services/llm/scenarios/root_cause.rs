//! Root Cause Analysis Scenario
//!
//! LLM-enhanced root cause analysis for query profile diagnostics.

use serde::{Deserialize, Serialize};
use std::collections::HashMap;

use crate::services::llm::models::LLMScenario;
use crate::services::llm::service::{LLMAnalysisRequestTrait, LLMAnalysisResponseTrait};

// ============================================================================
// System Prompt
// ============================================================================

pub const ROOT_CAUSE_SYSTEM_PROMPT: &str = r#"
ä½ æ˜¯ä¸€ä½ StarRocks OLAP æ•°æ®åº“çš„é«˜çº§æ€§èƒ½ä¸“å®¶ï¼Œæ‹¥æœ‰ 10 å¹´ä»¥ä¸Šçš„OLAPæŸ¥è¯¢è°ƒä¼˜ç»éªŒã€‚
ä½ éœ€è¦åˆ†æ Query Profile æ•°æ®ï¼Œè¯†åˆ«çœŸæ­£çš„æ ¹å› å¹¶ç»™å‡º**å¯ç›´æ¥æ‰§è¡Œ**çš„ä¼˜åŒ–å»ºè®®ã€‚

## ä½ æ”¶åˆ°çš„æ•°æ®
1. **å®Œæ•´ SQL**: åŸå§‹æŸ¥è¯¢è¯­å¥
2. **Profile åŸå§‹æ•°æ®**: å„ç®—å­çš„è¯¦ç»†æŒ‡æ ‡ï¼ˆæ—¶é—´ã€å†…å­˜ã€IOã€è¡Œæ•°ç­‰ï¼‰
3. **è§„åˆ™è¯Šæ–­ç»“æœ**: è§„åˆ™å¼•æ“å·²è¯†åˆ«çš„é—®é¢˜ï¼ˆä½œä¸ºå‚è€ƒï¼Œä¸è¦ç®€å•é‡å¤ï¼‰
4. **å½“å‰ Session å˜é‡**: é›†ç¾¤å½“å‰çš„é…ç½®å‚æ•°å€¼ï¼ˆ`session_variables` å­—æ®µï¼‰

## âš ï¸ é‡è¦ï¼šæ£€æŸ¥å½“å‰é…ç½®å†ç»™å»ºè®®
åœ¨ç»™å‡ºå‚æ•°è°ƒæ•´å»ºè®®å‰ï¼Œ**å¿…é¡»**æ£€æŸ¥ `session_variables` ä¸­çš„å½“å‰å€¼ï¼š
- å¦‚æœå‚æ•°å·²ç»æ˜¯æ¨èå€¼ï¼Œ**ä¸è¦é‡å¤å»ºè®®**
- ä¾‹å¦‚ï¼š`enable_scan_datacache=true` å·²å¯ç”¨ï¼Œå°±ä¸è¦å†å»ºè®®å¯ç”¨
- ä¾‹å¦‚ï¼š`parallel_fragment_exec_instance_num=16` å·²ç»è¾ƒå¤§ï¼Œè€ƒè™‘å…¶ä»–ä¼˜åŒ–æ–¹å‘

## ä½ çš„èŒè´£
1. **æ·±å…¥åˆ†æåŸå§‹ Profile æ•°æ®**ï¼Œä¸è¦åªçœ‹è§„åˆ™è¯Šæ–­ç»“æœ
2. **è¯†åˆ«è§„åˆ™å¼•æ“æœªå‘ç°çš„éšå¼æ ¹å› **ï¼Œå¦‚ç»Ÿè®¡ä¿¡æ¯è¿‡æœŸã€é…ç½®ä¸å½“ã€Join é¡ºåºé—®é¢˜
3. **å»ºç«‹å› æœå…³ç³»é“¾**ï¼Œè¯´æ˜é—®é¢˜çš„ä¼ å¯¼è·¯å¾„
4. **ç»™å‡ºå¯ç›´æ¥æ‰§è¡Œçš„ SQL æˆ–å‘½ä»¤**ï¼Œä¸è¦ç»™ç¬¼ç»Ÿçš„å»ºè®®

## å› æœæ¨æ–­åŸåˆ™
1. **æ—¶é—´å…ˆå**: ä¸Šæ¸¸ç®—å­å½±å“ä¸‹æ¸¸ç®—å­
2. **æ•°æ®ä¼ å¯¼**: æ•°æ®é‡/å€¾æ–œåº¦æ²¿æ‰§è¡Œè®¡åˆ’ä¼ å¯¼
3. **èµ„æºç«äº‰**: å¤šä¸ªç®—å­ç«äº‰åŒä¸€èµ„æºä¼šç›¸äº’å½±å“
4. **éšå¼å› ç´ **: ç»Ÿè®¡ä¿¡æ¯ã€é…ç½®ã€Join é¡ºåºæ˜¯å¸¸è§éšå¼æ ¹å› 

## âš ï¸ é‡è¦ï¼šåŒºåˆ†å†…è¡¨å’Œå¤–è¡¨
è¯·åŠ¡å¿…æŸ¥çœ‹ `scan_details` ä¸­çš„ `table_type` å­—æ®µï¼š
- **internal**: StarRocks åŸç”Ÿå†…è¡¨ï¼Œæ•°æ®å­˜å‚¨åœ¨æœ¬åœ° BE èŠ‚ç‚¹
- **external**: å¤–éƒ¨è¡¨ï¼ˆHive/Iceberg/HDFSï¼‰ï¼Œæ•°æ®åœ¨è¿œç¨‹å­˜å‚¨ï¼ˆHDFS/S3/OSSï¼‰
- **lake**: å­˜ç®—åˆ†ç¦»æ¶æ„è¡¨ï¼Œæ•°æ®åœ¨å…±äº«å­˜å‚¨

**ä¸åŒè¡¨ç±»å‹çš„ä¼˜åŒ–æ–¹å‘å®Œå…¨ä¸åŒï¼**
- å†…è¡¨ï¼šå…³æ³¨åˆ†æ¡¶ã€åˆ†åŒºã€ç‰©åŒ–è§†å›¾ã€ç»Ÿè®¡ä¿¡æ¯
- å¤–è¡¨ï¼šå…³æ³¨å°æ–‡ä»¶åˆå¹¶ã€DataCacheã€åˆ†åŒºè£å‰ªã€è°“è¯ä¸‹æ¨
- å¤–è¡¨ä¸æ”¯æŒ ALTER TABLE ä¿®æ”¹åˆ†æ¡¶ï¼å¤–è¡¨ä¼˜åŒ–éœ€è¦åœ¨ Hive/Spark ç«¯æ“ä½œï¼

## å¸¸è§æ ¹å› æ¨¡å¼ï¼ˆä»åŸå§‹æŒ‡æ ‡ä¸­è¯†åˆ«ï¼‰
| æ ¹å›  | Profile æŒ‡æ ‡ç‰¹å¾ | è§£å†³æ–¹æ¡ˆ |
|-----|-----------------|---------|
| ç»Ÿè®¡ä¿¡æ¯è¿‡æœŸ | EstimatedRows vs ActualRows å·®å¼‚å¤§ | ANALYZE TABLE xxxï¼ˆä»…å†…è¡¨ï¼‰|
| åˆ†æ¡¶é”®ä¸åˆç† | èŠ‚ç‚¹é—´ RowsRead/ProcessTime å·®å¼‚å¤§ | ALTER TABLEï¼ˆä»…å†…è¡¨ï¼‰|
| **å¤–è¡¨å°æ–‡ä»¶è¿‡å¤š** | ScanRanges æ•°é‡å¤§ã€IOTaskWaitTime é•¿ | **åœ¨ Hive/Spark ç«¯åˆå¹¶æ–‡ä»¶** |
| **å¤–è¡¨ç¼“å­˜æœªå‘½ä¸­** | FSIOBytesRead è¿œå¤§äº DataCacheReadBytes | SET enable_scan_datacache=true |
| å¹¶è¡Œåº¦ä¸è¶³ | å•èŠ‚ç‚¹ CPU é«˜ã€å…¶ä»–èŠ‚ç‚¹ç©ºé—² | SET parallel_fragment_exec_instance_num |
| Spill å‘ç”Ÿ | SpillBytes > 0ã€SpillTime > 0 | å¢åŠ å†…å­˜æˆ–ä¼˜åŒ–æŸ¥è¯¢ |
| åˆ†åŒºè£å‰ªå¤±æ•ˆ | PartitionPruned = falseã€ScanBytes å¤§ | æ£€æŸ¥ WHERE æ¡ä»¶ä¸­çš„åˆ†åŒºåˆ— |
| Join é¡ºåºä¸ä¼˜ | å¤§è¡¨åœ¨ Build ä¾§ã€ProbeRows >> BuildRows | è°ƒæ•´ Join Hint æˆ–æ›´æ–°ç»Ÿè®¡ä¿¡æ¯ |
| Broadcast è¿‡å¤§ | BroadcastBytes å¤§ã€ç½‘ç»œæ—¶é—´é•¿ | SET broadcast_row_limit |

## âš ï¸ å»ºè®®å¿…é¡»å¯æ‰§è¡Œä¸”å‚æ•°çœŸå®å­˜åœ¨
æ¯ä¸ªå»ºè®®å¿…é¡»æ˜¯ä»¥ä¸‹ç±»å‹ä¹‹ä¸€ï¼š
1. **SQL è¯­å¥**: å¯ç›´æ¥å¤åˆ¶æ‰§è¡Œçš„ SQL
2. **SET å‘½ä»¤**: è°ƒæ•´ Session å˜é‡
3. **DDL è¯­å¥**: ALTER TABLEã€CREATE INDEX ç­‰
4. **è¿ç»´å‘½ä»¤**: ANALYZEã€REFRESH MATERIALIZED VIEW ç­‰

### ğŸš« ç¦æ­¢ä½¿ç”¨ä¸å­˜åœ¨çš„å‚æ•°ï¼
**åªèƒ½ä½¿ç”¨ä»¥ä¸‹ StarRocks å®˜æ–¹æ”¯æŒçš„å‚æ•°ï¼š**

**Session å˜é‡ (SET xxx = yyy):**
- `query_mem_limit` - æŸ¥è¯¢å†…å­˜é™åˆ¶
- `query_timeout` - æŸ¥è¯¢è¶…æ—¶æ—¶é—´(ç§’)
- `enable_spill` - å¯ç”¨è½ç›˜
- `spill_mem_table_size` - è½ç›˜å†…å­˜è¡¨å¤§å°
- `pipeline_dop` - Pipeline å¹¶è¡Œåº¦
- `parallel_fragment_exec_instance_num` - Fragment å¹¶è¡Œå®ä¾‹æ•°
- `enable_scan_datacache` - å¯ç”¨ DataCache è¯»å–
- `enable_populate_datacache` - å¯ç”¨ DataCache å†™å…¥
- `enable_global_runtime_filter` - å¯ç”¨å…¨å±€ Runtime Filter
- `runtime_join_filter_push_down_limit` - Runtime Filter ä¸‹æ¨è¡Œæ•°é™åˆ¶
- `broadcast_row_limit` - Broadcast Join è¡Œæ•°é™åˆ¶
- `new_planner_agg_stage` - èšåˆé˜¶æ®µæ•°(0/1/2/3/4)

**SQL Hint (SELECT /*+ SET_VAR(xxx=yyy) */ ...):**
- ä¸Šè¿°æ‰€æœ‰ Session å˜é‡éƒ½å¯ä»¥ç”¨ Hint æ–¹å¼è®¾ç½®

**ALTER TABLE å±æ€§ (ä»…å†…è¡¨):**
- `replication_num` - å‰¯æœ¬æ•°
- `dynamic_partition.enable` - åŠ¨æ€åˆ†åŒº
- `bloom_filter_columns` - Bloom Filter åˆ—
- `colocate_with` - Colocate Group

**âŒ ä»¥ä¸‹æ˜¯ä¸å­˜åœ¨çš„å‚æ•°ï¼Œç¦æ­¢ä½¿ç”¨ï¼š**
- âŒ `enable_short_key_index` - ä¸å­˜åœ¨
- âŒ `enable_zone_map_index` - ä¸å­˜åœ¨
- âŒ `enable_bitmap_index` - ä¸å­˜åœ¨ï¼ˆå»ºç´¢å¼•ç”¨ CREATE INDEXï¼‰
- âŒ `enable_async_profile` - ä¸å­˜åœ¨
- âŒ `enable_query_debug_trace` - ä¸å­˜åœ¨

ç¤ºä¾‹ï¼ˆå¥½çš„å»ºè®®ï¼‰:
- `ANALYZE TABLE orders;`
- `SET parallel_fragment_exec_instance_num = 16;`
- `SELECT /*+ SET_VAR(query_timeout=300, enable_spill=true) */ ... FROM ...`
- åœ¨ Hive ç«¯æ‰§è¡Œ: `ALTER TABLE xxx CONCATENATE;` (åˆå¹¶å°æ–‡ä»¶)

ç¤ºä¾‹ï¼ˆä¸å¥½çš„å»ºè®®ï¼‰:
- âŒ "ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½" - å¤ªç¬¼ç»Ÿ
- âŒ "æ£€æŸ¥ç»Ÿè®¡ä¿¡æ¯" - æ²¡ç»™å…·ä½“å‘½ä»¤
- âŒ `ALTER TABLE xxx SET ("enable_short_key_index" = "true")` - å‚æ•°ä¸å­˜åœ¨ï¼

## âš ï¸ ä¸¥æ ¼ JSON è¾“å‡ºæ ¼å¼

```json
{
  "root_causes": [
    {
      "root_cause_id": "RC001",
      "description": "æ ¹å› æè¿°ï¼ŒåŸºäºåŸå§‹æŒ‡æ ‡åˆ†æ",
      "confidence": 0.85,
      "evidence": ["Profile æŒ‡æ ‡è¯æ®1", "æŒ‡æ ‡è¯æ®2"],
      "symptoms": ["S001", "G003"],
      "is_implicit": false
    }
  ],
  "causal_chains": [
    {
      "chain": ["æ ¹å› ", "â†’", "ä¸­é—´åŸå› ", "â†’", "ç—‡çŠ¶"],
      "explanation": "åŸºäº Profile æ•°æ®çš„å› æœåˆ†æ"
    }
  ],
  "recommendations": [
    {
      "priority": 1,
      "action": "å»ºè®®æ“ä½œçš„ç®€çŸ­æè¿°",
      "expected_improvement": "é¢„æœŸæ”¹å–„æ•ˆæœï¼ˆå®šé‡æè¿°ï¼‰",
      "sql_example": "å¯ç›´æ¥æ‰§è¡Œçš„ SQL æˆ–å‘½ä»¤"
    }
  ],
  "summary": "æ•´ä½“åˆ†ææ‘˜è¦ï¼Œé‡ç‚¹è¯´æ˜æ ¹å› å’Œä¼˜åŒ–æ–¹å‘",
  "hidden_issues": [
    {
      "issue": "è§„åˆ™å¼•æ“æœªå‘ç°çš„é—®é¢˜",
      "suggestion": "å¯æ‰§è¡Œçš„è§£å†³å‘½ä»¤"
    }
  ]
}
```

å­—æ®µè¯´æ˜:
- root_cause_id: "RC001", "RC002" æ ¼å¼
- evidence: **å¿…é¡»å¼•ç”¨å…·ä½“çš„ Profile æŒ‡æ ‡æ•°å€¼**
- symptoms: å…³è”çš„è§„åˆ™ ID
- is_implicit: true è¡¨ç¤ºè§„åˆ™å¼•æ“æœªæ£€æµ‹åˆ°
- priority: 1 ä¸ºæœ€é«˜ä¼˜å…ˆçº§
- sql_example: **å¿…å¡«**ï¼Œå¯ç›´æ¥æ‰§è¡Œçš„ SQL/å‘½ä»¤
"#;

// ============================================================================
// Request Types
// ============================================================================

/// Root Cause Analysis Request to LLM
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RootCauseAnalysisRequest {
    /// Query summary information
    pub query_summary: QuerySummaryForLLM,
    /// Raw profile data for deep analysis (NEW - åŸå§‹ Profile æ•°æ®)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub profile_data: Option<ProfileDataForLLM>,
    /// Execution plan (simplified for token efficiency)
    pub execution_plan: ExecutionPlanForLLM,
    /// Rule engine diagnostics (for reference, LLM should go deeper)
    pub rule_diagnostics: Vec<DiagnosticForLLM>,
    /// Key performance metrics
    pub key_metrics: KeyMetricsForLLM,
    /// Optional user question for follow-up
    #[serde(skip_serializing_if = "Option::is_none")]
    pub user_question: Option<String>,
}

impl LLMAnalysisRequestTrait for RootCauseAnalysisRequest {
    fn scenario(&self) -> LLMScenario {
        LLMScenario::RootCauseAnalysis
    }
    
    fn system_prompt(&self) -> &'static str {
        ROOT_CAUSE_SYSTEM_PROMPT
    }
    
    fn cache_key(&self) -> String {
        use std::hash::{Hash, Hasher};
        let mut hasher = std::collections::hash_map::DefaultHasher::new();
        self.sql_hash().hash(&mut hasher);
        self.profile_hash().hash(&mut hasher);
        format!("rca:{:x}", hasher.finish())
    }
    
    fn sql_hash(&self) -> String {
        use std::hash::{Hash, Hasher};
        let mut hasher = std::collections::hash_map::DefaultHasher::new();
        self.query_summary.sql_statement.hash(&mut hasher);
        format!("{:x}", hasher.finish())
    }
    
    fn profile_hash(&self) -> String {
        use std::hash::{Hash, Hasher};
        let mut hasher = std::collections::hash_map::DefaultHasher::new();
        // Hash key metrics
        self.query_summary.total_time_seconds.to_bits().hash(&mut hasher);
        self.query_summary.scan_bytes.hash(&mut hasher);
        self.rule_diagnostics.len().hash(&mut hasher);
        format!("{:x}", hasher.finish())
    }
}

/// Query summary for LLM analysis
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QuerySummaryForLLM {
    /// Full SQL statement (NOT truncated - LLM needs complete SQL for analysis)
    pub sql_statement: String,
    /// Query type: SELECT/INSERT/EXPORT/ANALYZE
    pub query_type: String,
    /// Total execution time in seconds
    pub total_time_seconds: f64,
    /// Total bytes scanned
    pub scan_bytes: u64,
    /// Output row count
    pub output_rows: u64,
    /// Number of BE nodes
    pub be_count: u32,
    /// Whether spill occurred
    pub has_spill: bool,
    /// Spill details if spill occurred
    #[serde(skip_serializing_if = "Option::is_none")]
    pub spill_bytes: Option<String>,
    /// Non-default session variables (important for analysis)
    #[serde(default, skip_serializing_if = "HashMap::is_empty")]
    pub session_variables: HashMap<String, String>,
}

// ============================================================================
// Raw Profile Data - NEW: åŸå§‹ Profile æ•°æ®
// ============================================================================

/// Raw profile data for LLM deep analysis
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProfileDataForLLM {
    /// All operator nodes with their metrics
    pub operators: Vec<OperatorDetailForLLM>,
    /// Cross-node time distribution (for detecting skew)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub time_distribution: Option<TimeDistributionForLLM>,
    /// Scan node details (tables, partitions, files)
    #[serde(default)]
    pub scan_details: Vec<ScanDetailForLLM>,
    /// Join node details (join type, build/probe stats)
    #[serde(default)]
    pub join_details: Vec<JoinDetailForLLM>,
    /// Aggregation node details
    #[serde(default)]
    pub agg_details: Vec<AggDetailForLLM>,
    /// Exchange (shuffle) details
    #[serde(default)]
    pub exchange_details: Vec<ExchangeDetailForLLM>,
}

/// Detailed operator information with all metrics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OperatorDetailForLLM {
    /// Operator name (SCAN, JOIN, AGG, etc.)
    pub operator: String,
    /// Plan node ID
    pub plan_node_id: i32,
    /// Execution time percentage
    pub time_pct: f64,
    /// Actual rows processed
    pub rows: u64,
    /// Estimated rows (for cardinality error detection)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub estimated_rows: Option<u64>,
    /// Memory used in bytes
    #[serde(skip_serializing_if = "Option::is_none")]
    pub memory_bytes: Option<u64>,
    /// All key metrics (raw from profile)
    pub metrics: HashMap<String, String>,
}

/// Time distribution across instances for skew detection
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TimeDistributionForLLM {
    /// Max time across instances
    pub max_time_ms: f64,
    /// Min time across instances
    pub min_time_ms: f64,
    /// Average time
    pub avg_time_ms: f64,
    /// Skew ratio (max/avg)
    pub skew_ratio: f64,
    /// Per-instance times for top operators
    #[serde(default)]
    pub per_instance: Vec<InstanceTimeForLLM>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InstanceTimeForLLM {
    pub operator: String,
    pub instance_id: i32,
    pub time_ms: f64,
    pub rows: u64,
}

/// Scan operator details
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ScanDetailForLLM {
    pub plan_node_id: i32,
    pub table_name: String,
    /// OlapScan / HdfsScan / ConnectorScan etc.
    pub scan_type: String,
    /// Table storage type: "internal" (StarRocks native), "external" (Hive/Iceberg/HDFS), "lake" (shared-data)
    /// This is CRITICAL for LLM to give correct suggestions!
    pub table_type: String,
    /// Total rows read
    pub rows_read: u64,
    /// Rows after filtering
    pub rows_returned: u64,
    /// Filter ratio
    pub filter_ratio: f64,
    /// Scan ranges (file/tablet count)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub scan_ranges: Option<u64>,
    /// Bytes read
    #[serde(skip_serializing_if = "Option::is_none")]
    pub bytes_read: Option<u64>,
    /// IO wait time
    #[serde(skip_serializing_if = "Option::is_none")]
    pub io_time_ms: Option<f64>,
    /// Cache hit rate (DataCache for external, PageCache for internal)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub cache_hit_rate: Option<f64>,
    /// Predicates applied
    #[serde(skip_serializing_if = "Option::is_none")]
    pub predicates: Option<String>,
    /// Partition pruning info
    #[serde(skip_serializing_if = "Option::is_none")]
    pub partitions_scanned: Option<String>,
    /// For external tables: catalog.database.table format
    #[serde(skip_serializing_if = "Option::is_none")]
    pub full_table_path: Option<String>,
}

/// Join operator details
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct JoinDetailForLLM {
    pub plan_node_id: i32,
    /// HASH_JOIN, CROSS_JOIN, etc.
    pub join_type: String,
    /// Build side rows
    pub build_rows: u64,
    /// Probe side rows
    pub probe_rows: u64,
    /// Output rows
    pub output_rows: u64,
    /// Hash table memory
    #[serde(skip_serializing_if = "Option::is_none")]
    pub hash_table_memory: Option<u64>,
    /// Is broadcast join
    #[serde(default)]
    pub is_broadcast: bool,
    /// Runtime filter info
    #[serde(skip_serializing_if = "Option::is_none")]
    pub runtime_filter: Option<String>,
}

/// Aggregation operator details
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AggDetailForLLM {
    pub plan_node_id: i32,
    /// Input rows
    pub input_rows: u64,
    /// Output rows after aggregation
    pub output_rows: u64,
    /// Aggregation ratio (output/input)
    pub agg_ratio: f64,
    /// GROUP BY keys
    #[serde(skip_serializing_if = "Option::is_none")]
    pub group_by_keys: Option<String>,
    /// Hash table memory
    #[serde(skip_serializing_if = "Option::is_none")]
    pub hash_table_memory: Option<u64>,
    /// Is streaming agg
    #[serde(default)]
    pub is_streaming: bool,
}

/// Exchange (shuffle) operator details
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExchangeDetailForLLM {
    pub plan_node_id: i32,
    /// SHUFFLE, BROADCAST, GATHER
    pub exchange_type: String,
    /// Data sent bytes
    pub bytes_sent: u64,
    /// Rows sent
    pub rows_sent: u64,
    /// Network time
    #[serde(skip_serializing_if = "Option::is_none")]
    pub network_time_ms: Option<f64>,
}

/// Simplified execution plan for LLM
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExecutionPlanForLLM {
    /// DAG description in text format
    /// e.g., "SCAN(orders) -> JOIN -> SCAN(customers) -> AGG -> SINK"
    pub dag_description: String,
    /// Hotspot nodes (time_percentage > 15%)
    #[serde(default)]
    pub hotspot_nodes: Vec<HotspotNodeForLLM>,
}

/// Hotspot node information
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HotspotNodeForLLM {
    /// Operator name, e.g., "HASH_JOIN"
    pub operator: String,
    /// Plan node ID
    pub plan_node_id: i32,
    /// Time percentage (0-100)
    pub time_percentage: f64,
    /// Key metrics relevant to this operator
    #[serde(default, skip_serializing_if = "HashMap::is_empty")]
    pub key_metrics: HashMap<String, String>,
    /// Upstream operator names
    #[serde(default)]
    pub upstream_operators: Vec<String>,
}

/// Rule engine diagnostic result for LLM
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DiagnosticForLLM {
    /// Rule ID, e.g., "S001"
    pub rule_id: String,
    /// Severity: Error/Warning/Info
    pub severity: String,
    /// Affected operator
    pub operator: String,
    /// Plan node ID
    #[serde(skip_serializing_if = "Option::is_none")]
    pub plan_node_id: Option<i32>,
    /// Diagnostic message
    pub message: String,
    /// Evidence that triggered the rule
    #[serde(default, skip_serializing_if = "HashMap::is_empty")]
    pub evidence: HashMap<String, String>,
}

/// Key performance metrics
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct KeyMetricsForLLM {
    /// Data skew metrics
    #[serde(skip_serializing_if = "Option::is_none")]
    pub skew_metrics: Option<SkewMetricsForLLM>,
    /// IO metrics
    #[serde(skip_serializing_if = "Option::is_none")]
    pub io_metrics: Option<IOMetricsForLLM>,
    /// Memory metrics
    #[serde(skip_serializing_if = "Option::is_none")]
    pub memory_metrics: Option<MemoryMetricsForLLM>,
    /// Cardinality estimation errors
    #[serde(default, skip_serializing_if = "Vec::is_empty")]
    pub cardinality_errors: Vec<CardinalityErrorForLLM>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SkewMetricsForLLM {
    pub max_rows: u64,
    pub min_rows: u64,
    pub avg_rows: f64,
    pub skew_ratio: f64,
    pub affected_operator: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct IOMetricsForLLM {
    pub total_bytes_read: u64,
    pub cache_hit_rate: f64,
    pub io_time_percentage: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MemoryMetricsForLLM {
    pub peak_memory_bytes: u64,
    pub spill_bytes: u64,
    pub hash_table_memory: u64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CardinalityErrorForLLM {
    pub operator: String,
    pub estimated_rows: u64,
    pub actual_rows: u64,
    pub error_ratio: f64,
}

// ============================================================================
// Response Types
// ============================================================================

/// Root Cause Analysis Response from LLM
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RootCauseAnalysisResponse {
    /// Identified root causes
    #[serde(default)]
    pub root_causes: Vec<LLMRootCause>,
    /// Causal chains with explanations
    #[serde(default)]
    pub causal_chains: Vec<LLMCausalChain>,
    /// Prioritized recommendations
    #[serde(default)]
    pub recommendations: Vec<LLMRecommendation>,
    /// Summary in natural language
    #[serde(default)]
    pub summary: String,
    /// Hidden issues not detected by rule engine
    #[serde(default)]
    pub hidden_issues: Vec<LLMHiddenIssue>,
}

impl LLMAnalysisResponseTrait for RootCauseAnalysisResponse {
    fn summary(&self) -> &str {
        &self.summary
    }
    
    fn confidence(&self) -> Option<f64> {
        if self.root_causes.is_empty() {
            None
        } else {
            Some(self.root_causes.iter().map(|r| r.confidence).sum::<f64>() / self.root_causes.len() as f64)
        }
    }
}

/// Root cause identified by LLM
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LLMRootCause {
    /// Unique ID for this root cause
    pub root_cause_id: String,
    /// Description of the root cause
    pub description: String,
    /// Confidence score (0.0 - 1.0)
    pub confidence: f64,
    /// Evidence supporting this conclusion
    #[serde(default)]
    pub evidence: Vec<String>,
    /// Symptom rule IDs caused by this root cause
    #[serde(default)]
    pub symptoms: Vec<String>,
    /// Whether this is an implicit root cause (not detected by rules)
    #[serde(default)]
    pub is_implicit: bool,
}

/// Causal chain with explanation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LLMCausalChain {
    /// Chain representation, e.g., ["ç»Ÿè®¡ä¿¡æ¯è¿‡æœŸ", "â†’", "Joiné¡ºåºä¸ä¼˜", "â†’", "å†…å­˜è¿‡é«˜"]
    pub chain: Vec<String>,
    /// Natural language explanation
    pub explanation: String,
}

/// Recommendation from LLM
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LLMRecommendation {
    /// Priority (1 = highest)
    pub priority: u32,
    /// Action to take
    pub action: String,
    /// Expected improvement
    #[serde(default)]
    pub expected_improvement: String,
    /// SQL example if applicable
    #[serde(skip_serializing_if = "Option::is_none")]
    pub sql_example: Option<String>,
}

/// Hidden issue not detected by rule engine
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LLMHiddenIssue {
    /// Issue description
    pub issue: String,
    /// Suggested action
    pub suggestion: String,
}

// ============================================================================
// Builder for RootCauseAnalysisRequest
// ============================================================================

impl RootCauseAnalysisRequest {
    /// Create a new builder
    pub fn builder() -> RootCauseAnalysisRequestBuilder {
        RootCauseAnalysisRequestBuilder::default()
    }
}

#[derive(Default)]
pub struct RootCauseAnalysisRequestBuilder {
    query_summary: Option<QuerySummaryForLLM>,
    profile_data: Option<ProfileDataForLLM>,
    execution_plan: Option<ExecutionPlanForLLM>,
    rule_diagnostics: Vec<DiagnosticForLLM>,
    key_metrics: KeyMetricsForLLM,
    user_question: Option<String>,
}

impl RootCauseAnalysisRequestBuilder {
    pub fn query_summary(mut self, summary: QuerySummaryForLLM) -> Self {
        self.query_summary = Some(summary);
        self
    }
    
    pub fn profile_data(mut self, data: ProfileDataForLLM) -> Self {
        self.profile_data = Some(data);
        self
    }
    
    pub fn execution_plan(mut self, plan: ExecutionPlanForLLM) -> Self {
        self.execution_plan = Some(plan);
        self
    }
    
    pub fn add_diagnostic(mut self, diag: DiagnosticForLLM) -> Self {
        self.rule_diagnostics.push(diag);
        self
    }
    
    pub fn diagnostics(mut self, diags: Vec<DiagnosticForLLM>) -> Self {
        self.rule_diagnostics = diags;
        self
    }
    
    pub fn key_metrics(mut self, metrics: KeyMetricsForLLM) -> Self {
        self.key_metrics = metrics;
        self
    }
    
    pub fn user_question(mut self, question: impl Into<String>) -> Self {
        self.user_question = Some(question.into());
        self
    }
    
    pub fn build(self) -> Result<RootCauseAnalysisRequest, &'static str> {
        Ok(RootCauseAnalysisRequest {
            query_summary: self.query_summary.ok_or("query_summary is required")?,
            profile_data: self.profile_data,
            execution_plan: self.execution_plan.ok_or("execution_plan is required")?,
            rule_diagnostics: self.rule_diagnostics,
            key_metrics: self.key_metrics,
            user_question: self.user_question,
        })
    }
}
